# ğŸ¬ IMDB Rating Prediction - Machine Learning con SparkML

Modelo de predicciÃ³n de calificaciones IMDB usando Apache Spark y tÃ©cnicas avanzadas de Feature Engineering.

---

## ğŸ“Š Resumen del Proyecto

**Objetivo:** Predecir la calificaciÃ³n promedio (`avg_vote`) de pelÃ­culas en IMDB usando features textuales y numÃ©ricas.

**Dataset:**
- 85,855 pelÃ­culas (dataset completo)
- 69,107 pelÃ­culas (despuÃ©s de limpieza - 80.49% retenciÃ³n)
- 70 columnas originales
- Target: `avg_vote` (escala 1.0-10.0, media ~5.9)

**Resultado Final:**
- ğŸ† **Mejor modelo:** Gradient Boosted Trees
- ğŸ“ˆ **RÂ² = 0.9945** (explica 99.45% de la varianza)
- ğŸ“‰ **RMSE = 0.0912** (error promedio ~0.09 puntos)
- âš¡ **Tiempo total:** ~1.2 minutos

---

## ğŸ”§ Arquitectura TÃ©cnica

### Features Engineering (~130 features total)

#### 1ï¸âƒ£ **Features de Texto (100 features)**
- **TF-IDF Unigrams** en columna `description`
- TokenizaciÃ³n + StopWords removal
- HashingTF con 100 features
- IDF para capturar importancia semÃ¡ntica

#### 2ï¸âƒ£ **Features CategÃ³ricas (19 features)**
- **Genre:** Feature Hashing (16 features)
  - Maneja 1,117 combinaciones Ãºnicas sin OutOfMemory
  - ReducciÃ³n de cardinalidad: Top 30 + "Other"
  
- **Director:** Target Encoding (1 feature)
  - Reduce 10,000+ directores a 1 feature numÃ©rica
  - Smoothing factor = 10 para evitar overfitting
  
- **Actors:** Target Encoding (1 feature)
  - Reduce 55,457 actores a 1 feature numÃ©rica
  - Captura "prestigio" promedio del elenco
  
- **Duration Category:** StringIndexer (1 feature)
  - CategorÃ­as: short (â‰¤90 min), medium (90-120), long (>120)

#### 3ï¸âƒ£ **Features NumÃ©ricas (11 features)**

**Originales:**
- `duration` - DuraciÃ³n en minutos
- `votes` - NÃºmero de votos
- `reviews_from_users` - Reviews de usuarios
- `reviews_from_critics` - Reviews de crÃ­ticos
- `year_clean` - AÃ±o de estreno (limpio)

**Derivadas (Feature Engineering):**
- `log_votes` = logâ‚(votes + 1) - Normaliza distribuciÃ³n
- `votes_per_review` = votes / (reviews_users + reviews_critics + 1)
- `review_ratio` = reviews_users / (reviews_critics + 1)
- `decade` = (year_clean / 10) Ã— 10 - Agrupa por dÃ©cada
- `is_recent` = 1 si year â‰¥ 2015, else 0
- `is_old_classic` = 1 si year â‰¤ 1980, else 0

### NormalizaciÃ³n
- **StandardScaler** aplicado a todas las features
- `withStd=true, withMean=false` (Ã³ptimo para sparse vectors)

---

## ğŸ¤– Modelos Implementados

### 1. Ridge Regression (Baseline)
```scala
LinearRegression(
  maxIter = 100,
  regParam = 0.1,        // L2 regularization
  elasticNetParam = 0.0  // Pure Ridge
)
```
**Resultados:**
- RMSE: 0.1265
- RÂ²: 0.9895
- Tiempo: 0.11 min

### 2. Random Forest Regressor
```scala
RandomForestRegressor(
  numTrees = 30,
  maxDepth = 8,
  minInstancesPerNode = 10,
  subsamplingRate = 0.8  // OptimizaciÃ³n de memoria
)
```
**Resultados:**
- RMSE: 0.1702
- RÂ²: 0.9810
- Tiempo: 0.24 min

### 3. Gradient Boosted Trees (ğŸ† Mejor)
```scala
GBTRegressor(
  maxIter = 50,
  maxDepth = 5,
  stepSize = 0.1,        // Learning rate
  subsamplingRate = 0.8
)
```
**Resultados:**
- RMSE: 0.0912
- RÂ²: 0.9945
- Tiempo: 0.82 min

### 4. Ensemble Model
```scala
prediction_ensemble = 0.2Ã—Ridge + 0.3Ã—RF + 0.5Ã—GBT
```
**Resultados:**
- RMSE: 0.0977
- RÂ²: 0.9937
- Combina fortalezas de mÃºltiples modelos

---

## ğŸš€ EjecuciÃ³n

### Prerequisitos
- Apache Spark 3.3.1+
- Scala 2.12.15+
- 14GB+ RAM disponible

### Iniciar Spark Shell
```bash
spark-shell \
  --driver-memory 14g \
  --executor-memory 14g \
  --conf spark.memory.fraction=0.8 \
  --conf spark.memory.storageFraction=0.2 \
  --conf spark.sql.shuffle.partitions=50 \
  --conf spark.driver.maxResultSize=2g
```

### Ejecutar Modelo
```scala
:load ml_prediction/IMDBPredictionModelSimplified.scala
IMDBPredictionModelSimplified.main(Array())
```

### Validar Datos (Opcional)
```scala
:load ml_prediction/DataValidation.scala
DataValidation.main(Array())
```

---

## ğŸ“ Estructura del Proyecto

```
ml_prediction/
â”œâ”€â”€ README.md                              # Este archivo
â”œâ”€â”€ DataValidation.scala                   # Script de validaciÃ³n de datos
â”œâ”€â”€ IMDBPredictionModelSimplified.scala   # ğŸ¯ MODELO FINAL
â””â”€â”€ resultados/
    â”œâ”€â”€ reporte_simplificado.txt          # Reporte comparativo
    â”œâ”€â”€ simplified_baseline_predictions.txt
    â”œâ”€â”€ simplified_rf_predictions.txt
    â”œâ”€â”€ simplified_gbt_predictions.txt
    â””â”€â”€ simplified_ensemble_predictions.txt
```

---

## ğŸ’¡ TÃ©cnicas Clave para Manejo de Memoria

### Problema Original
- **OutOfMemoryError** con Random Forest debido a alta cardinalidad de features categÃ³ricas
- `director` (10,000+ valores), `actors` (55,457 valores), `genre` (1,117 valores)
- StringIndexer + OneHotEncoder creaban features explosivas

### Soluciones Implementadas

#### 1ï¸âƒ£ **Target Encoding con Smoothing**
```scala
encoded_value = (category_mean Ã— count + global_mean Ã— 10) / (count + 10)
```
- Reduce cualquier cardinalidad a 1 feature numÃ©rica
- Captura "valor promedio" de la categorÃ­a
- Smoothing evita overfitting en categorÃ­as raras

#### 2ï¸âƒ£ **Feature Hashing**
```scala
FeatureHasher(numFeatures = 16)
```
- DimensiÃ³n fija independiente de cardinalidad
- No requiere mantener diccionarios en memoria
- Tolerante a colisiones con hash functions

#### 3ï¸âƒ£ **ReducciÃ³n de Cardinalidad**
```scala
top30_genres + "Other"
```
- Agrupa categorÃ­as raras en "Other"
- Mantiene informaciÃ³n de categorÃ­as frecuentes

#### 4ï¸âƒ£ **Subsampling**
```scala
subsamplingRate = 0.8
```
- Cada Ã¡rbol/iteraciÃ³n usa solo 80% de datos
- Reduce memoria y mejora generalizaciÃ³n

---

## ğŸ“ˆ Resultados Comparativos

| Modelo | RMSE â†“ | MAE â†“ | RÂ² â†‘ | Tiempo | Mejora vs Baseline |
|--------|--------|-------|------|--------|-------------------|
| **GBT** | **0.0912** | **0.0401** | **0.9945** | 0.82 min | **27.95%** |
| Ensemble | 0.0977 | 0.0555 | 0.9937 | ~1 min | 22.77% |
| Ridge | 0.1265 | 0.0951 | 0.9895 | 0.11 min | - |
| Random Forest | 0.1702 | 0.1025 | 0.9810 | 0.24 min | -34.55% |

---

## ğŸ“ Lecciones Aprendidas

### âœ… Funciona Bien
1. **Target Encoding** para high-cardinality categoricals
2. **Feature Hashing** para control de memoria
3. **TF-IDF** captura informaciÃ³n semÃ¡ntica de texto
4. **Feature Engineering** (log_votes, ratios) mejora significativamente
5. **GBT** supera a Random Forest en este dataset

### âš ï¸ Limitaciones Identificadas
1. Random Forest requiere mÃ¡s memoria con features categÃ³ricas
2. Grid Search con CrossValidation es prohibitivo en tiempo
3. Bi-gramas (n-grams=2) no justifican el costo computacional
4. OneHotEncoder explota con alta cardinalidad

### ğŸš€ Posibles Mejoras Futuras
1. Word2Vec en lugar de TF-IDF para semÃ¡ntica profunda
2. AnÃ¡lisis de sentimiento en `description`
3. Features de presupuesto/recaudaciÃ³n (si disponibles)
4. InformaciÃ³n de premios y nominaciones
5. Tuning fino de hiperparÃ¡metros (requiere cluster)

---

## ğŸ“Š Feature Importance (Top 10 - GBT)

*Los Ã­ndices de features estÃ¡n en el vector assembler final*

1. **Feature 51** (29.78%) - Probablemente `log_votes`
2. **Feature 52** (25.89%) - Probablemente `votes`
3. **Feature 54** (19.57%) - Features numÃ©ricas derivadas
4. **Feature 50** (17.69%) - TF-IDF components
5. **Feature 53** (5.14%) - Categorical encoded
6. Resto < 1% cada una

**ConclusiÃ³n:** Features numÃ©ricas (votes, reviews) son las mÃ¡s predictivas, seguidas de text features (description).

---

## ğŸ‘¨â€ğŸ’» Autor

**Victor W. Key**
- Dataset: IMDB Movies Extensive Dataset
- Framework: Apache Spark 3.3.1 + SparkML
- Fecha: Noviembre 2025

---

## ğŸ“„ Licencia

Proyecto educativo - AnÃ¡lisis de Big Data con Spark

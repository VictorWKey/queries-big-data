import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// Script para identificar quÃ© features corresponden a cada Ã­ndice
// :load ml_prediction/IdentificarFeatures.scala
// IdentificarFeatures.main(Array())

object IdentificarFeatures {
  
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("Identificar Features")
      .master("local[*]")
      .config("spark.driver.memory", "4g")
      .getOrCreate()
    
    spark.sparkContext.setLogLevel("ERROR")
    
    println("=" * 80)
    println("ğŸ” IDENTIFICACIÃ“N DE FEATURES POR ÃNDICE")
    println("=" * 80)
    println()
    
    println("ğŸ“Š MAPA DE FEATURES (segÃºn VectorAssembler):")
    println("-" * 80)
    println()
    
    // Basado en el cÃ³digo de IMDBPredictionModelNOLEAKAGE.scala
    val featureMap = Map(
      "0-99" -> "description_features (TF-IDF)",
      "100-115" -> "genre_features (FeatureHasher - 16 features)",
      "116" -> "director_encoded (Target Encoding)",
      "117" -> "actors_encoded (Target Encoding)",
      "118" -> "duration (numÃ©rica)",
      "119" -> "duration_indexed (categÃ³rica)",
      "120" -> "year_clean (numÃ©rica)",
      "121" -> "decade (numÃ©rica)",
      "122" -> "is_recent (binaria)",
      "123" -> "is_old_classic (binaria)"
    )
    
    println("Ãndice    Feature                              Tipo")
    println("-" * 80)
    println("0-99      description_features                 TF-IDF (100 features)")
    println("100-115   genre_features                       FeatureHasher (16 features)")
    println("116       director_encoded                     Target Encoding")
    println("117       actors_encoded                       Target Encoding âš ï¸")
    println("118       duration                             NumÃ©rica")
    println("119       duration_indexed                     CategÃ³rica")
    println("120       year_clean                           NumÃ©rica")
    println("121       decade                               NumÃ©rica")
    println("122       is_recent                            Binaria")
    println("123       is_old_classic                       Binaria")
    println()
    
    println("=" * 80)
    println("ğŸ”´ ANÃLISIS DE FEATURE IMPORTANCES")
    println("=" * 80)
    println()
    
    println("Feature 117 (74% importancia) = actors_encoded")
    println("Feature 116 (11% importancia) = director_encoded")
    println()
    
    println("âš ï¸  PROBLEMA IDENTIFICADO:")
    println("-" * 80)
    println("El TARGET ENCODING estÃ¡ causando data leakage indirecto!")
    println()
    println("EXPLICACIÃ“N:")
    println("  1. Target Encoding calcula: encoding = mean(avg_vote) por categorÃ­a")
    println("  2. Aunque se calcula solo en TRAIN, sigue siendo el PROMEDIO del target")
    println("  3. Los actores/directores 'buenos' tienen encoding alto â†’ rating alto")
    println("  4. El modelo aprende: encoding_alto â†’ rating_alto (casi tautolÃ³gico)")
    println()
    println("EVIDENCIA:")
    println("  â€¢ actors_encoded domina el 74% del modelo")
    println("  â€¢ director_encoded contribuye otro 11%")
    println("  â€¢ Total Target Encoding: 85% de importancia")
    println()
    
    println("=" * 80)
    println("ğŸ§ª PRUEBA: CORRELACIÃ“N DIRECTA")
    println("=" * 80)
    println()
    
    // Cargar datos y verificar
    val moviesPath = "IMDB-Movies-Extensive-Dataset-Analysis/data1/IMDb movies.csv"
    val ratingsPath = "IMDB-Movies-Extensive-Dataset-Analysis/data1/IMDb ratings.csv"
    
    val movies = spark.read
      .option("header", "true")
      .option("inferSchema", "true")
      .option("escape", "\"")
      .option("multiLine", "true")
      .csv(moviesPath)
    
    val ratings = spark.read
      .option("header", "true")
      .option("inferSchema", "true")
      .csv(ratingsPath)
    
    val df = movies.join(ratings, Seq("imdb_title_id"), "inner")
      .na.drop(Seq("actors", "avg_vote"))
    
    // Calcular encoding de actores manualmente
    val actorsMean = df.groupBy("actors")
      .agg(mean("avg_vote").alias("actors_avg_rating"))
    
    val dfWithEncoding = df.join(actorsMean, "actors")
    
    val correlation = dfWithEncoding.stat.corr("avg_vote", "actors_avg_rating")
    
    println(s"CorrelaciÃ³n entre avg_vote y actors_encoded: ${correlation}")
    println()
    
    if (correlation > 0.9) {
      println("ğŸ”´ CORRELACIÃ“N MUY ALTA (> 0.9) â†’ TARGET ENCODING = DATA LEAKAGE")
      println()
      println("EXPLICACIÃ“N TÃ‰CNICA:")
      println("  Target Encoding usa directamente el promedio del target")
      println("  â†’ actors_encoded â‰ˆ avg_vote (por construcciÃ³n)")
      println("  â†’ El modelo aprende una relaciÃ³n circular")
      println()
    } else if (correlation > 0.7) {
      println("ğŸŸ¡ CORRELACIÃ“N ALTA (> 0.7) â†’ TARGET ENCODING = LEAKAGE MODERADO")
    } else {
      println("âœ… CorrelaciÃ³n aceptable")
    }
    
    println("=" * 80)
    println("ğŸ’¡ SOLUCIÃ“N RECOMENDADA")
    println("=" * 80)
    println()
    println("OPCIÃ“N 1: ELIMINAR Target Encoding")
    println("-" * 80)
    println("  âŒ Quitar director_encoded y actors_encoded")
    println("  âœ… Usar solo: description, genre, duration, year")
    println("  â†’ RÂ² esperado: 0.30-0.40 (realista)")
    println()
    
    println("OPCIÃ“N 2: Target Encoding con Smoothing Fuerte")
    println("-" * 80)
    println("  âš ï¸  Aumentar smoothing factor (de 10 a 100)")
    println("  âš ï¸  Usar K-Fold Target Encoding (evitar overfitting)")
    println("  â†’ RÂ² esperado: 0.50-0.60")
    println()
    
    println("OPCIÃ“N 3: Frequency Encoding (sin usar target)")
    println("-" * 80)
    println("  âœ… Codificar por frecuencia de apariciÃ³n")
    println("  âœ… NO usa valores del target")
    println("  â†’ RÂ² esperado: 0.35-0.45")
    println()
    
    println("=" * 80)
    println("ğŸ¯ CONCLUSIÃ“N FINAL")
    println("=" * 80)
    println()
    println("El problema NO es votes/reviews (esas estÃ¡n limpias)")
    println("El problema ES el TARGET ENCODING de actors/director")
    println()
    println("Target Encoding es una forma sutil de data leakage porque:")
    println("  1. Usa directamente el promedio del target")
    println("  2. Crea una correlaciÃ³n casi perfecta por construcciÃ³n")
    println("  3. No refleja capacidad predictiva real")
    println()
    println("RECOMENDACIÃ“N: Ejecutar modelo SIN target encoding")
    println("(Ver: IMDBPredictionModelSINTARGETENCODING.scala)")
    println()
    println("=" * 80)
    
    spark.stop()
  }
}
